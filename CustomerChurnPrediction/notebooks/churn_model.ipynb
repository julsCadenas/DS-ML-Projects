{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Customer Churn Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **What is customer churn?**  \n",
    "Customer churn refers to the percentage of customers who stop using a company's product or service within a given time frame. This metric helps businesses gauge customer satisfaction and loyalty while also providing insights into potential revenue fluctuations.\n",
    "\n",
    "Churn is especially critical for subscription-based businesses, such as SaaS companies, which rely on recurring revenue. Understanding churn patterns allows them to anticipate financial impact and take proactive measures.\n",
    "\n",
    "Also known as customer attrition, churn is the opposite of customer retention, which focuses on maintaining long-term customer relationships. Reducing churn should be a key part of any customer engagement strategy, ensuring consistent interactions between businesses and their customers, whether online or in person.\n",
    "\n",
    "A strong customer retention plan plays a crucial role in minimizing churn. Companies should track churn rates regularly to assess their risk of revenue loss and identify areas for improvement.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Source:** IBM. Customer Churn. Retrieved from https://www.ibm.com/think/topics/customer-churn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_columns',None)\n",
    "\n",
    "train_path = '../data/CustomerChurnDataset/customer_churn_dataset-testing-master.csv'\n",
    "test_path = '../data/CustomerChurnDataset/customer_churn_dataset-training-master.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we saw in our EDA that we only have 1 row of missing value/s from test_df lets drop that row.  \n",
    "Prepare the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.dropna(inplace=True)\n",
    "\n",
    "y_train = train_df['Churn']\n",
    "x_train = train_df.drop(columns=['Churn'])\n",
    "\n",
    "y_test = test_df['Churn']\n",
    "x_test = test_df.drop(columns=['Churn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Subscription Type', 'Contract Length']\n",
      "['CustomerID', 'Age', 'Tenure', 'Usage Frequency', 'Support Calls', 'Payment Delay', 'Total Spend', 'Last Interaction']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = x_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = x_train.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "print(categorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the preprocessor for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the hyperparameters for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'eta': hp.uniform('eta', 0.01,0.2),\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "    'gamma': hp.uniform ('gamma', 1,9),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "    'subsample': hp.uniform('subsample', 0.5,1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 1000, 10),\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    # convert the quniforms into int since they are float\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['min_child_weight'] = int(params['min_child_weight'])\n",
    "    params['reg_alpha'] = int(params['reg_alpha'])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', XGBClassifier(**params, use_label_encoder=False, eval_metric=\"logloss\"))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"Params: {params}, AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "    return {'loss': -auc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(\n",
    "    fn = objective,\n",
    "    space = params_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 100,\n",
    "    trials = trials\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Best Hyperparameters Found:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_params = {\"max_depth\", \"n_estimators\", \"min_child_weight\", \"reg_alpha\"}\n",
    "\n",
    "def convert_params(params):\n",
    "    return {k: int(v) if k in int_params else float(v) for k, v in params.items()}\n",
    "\n",
    "best_params = convert_params(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', XGBClassifier(**best_params))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 0.7422\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.70      0.70    190833\n",
      "         1.0       0.77      0.78      0.77    249999\n",
      "\n",
      "    accuracy                           0.74    440832\n",
      "   macro avg       0.74      0.74      0.74    440832\n",
      "weighted avg       0.74      0.74      0.74    440832\n",
      "\n",
      "XGBoost AUC-ROC: 0.7369742139671895\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(test, pred):\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "\n",
    "    print(f\"Final Model Accuracy: {accuracy:.4f}\")\n",
    "    print(\"XGBoost Classification Report:\\n\", classification_report(test, pred))\n",
    "    print(\"XGBoost AUC-ROC:\", roc_auc_score(test, pred))\n",
    "    \n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
