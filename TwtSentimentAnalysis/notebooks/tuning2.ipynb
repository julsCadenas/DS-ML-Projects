{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c369452",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning & Cross Validation** (2nd attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814fc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b960a2",
   "metadata": {},
   "source": [
    "Define model creation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d688b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_optuna(trial, input_dim=10000):\n",
    "\n",
    "    embedding_dim = trial.suggest_int('embedding_dim', 32, 256, step=32)\n",
    "    lstm_units = trial.suggest_int('lstm_units', 32, 256, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.8)\n",
    "    dense_units = trial.suggest_int('dense_units', 16, 128, step=16)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=input_dim, output_dim=embedding_dim),\n",
    "        LSTM(lstm_units, return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, batch_size\n",
    "\n",
    "print(\"Model creation function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a409722",
   "metadata": {},
   "source": [
    "Define objective function for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    model, batch_size = create_model_optuna(trial)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train)):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            epochs=12,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        best_val_acc = max(history.history['val_accuracy'])\n",
    "        cv_scores.append(best_val_acc)\n",
    "        \n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        if fold < 4:\n",
    "            model, _ = create_model_optuna(trial)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "print(\"Objective function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b9ad9",
   "metadata": {},
   "source": [
    "Load and prepare your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b508e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/twt.csv'\n",
    "column_names = ['sentiment', 'id', 'date', 'flag', 'user', 'text']\n",
    "df = pd.read_csv(dataset_path, encoding='latin', delimiter=',', names=column_names)\n",
    "\n",
    "df = df.drop(['id', 'date', 'flag', 'user'], axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "sentiment_critical = {\n",
    "    'not', 'no', 'never', 'nothing', 'nobody', 'none', 'nowhere', 'neither',\n",
    "    'very', 'really', 'quite', 'rather', 'extremely', 'incredibly', 'absolutely',\n",
    "    'but', 'however', 'although', 'though', 'yet', 'except',\n",
    "    'too', 'so', 'such', 'more', 'most', 'less', 'least',\n",
    "    'only', 'just', 'still', 'even', 'again'\n",
    "}\n",
    "\n",
    "negative_contractions = {\n",
    "    \"don't\", \"won't\", \"can't\", \"shouldn't\", \"wouldn't\", \"couldn't\",\n",
    "    \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"hasn't\", \"haven't\",\n",
    "    \"hadn't\", \"doesn't\", \"didn't\", \"won't\", \"shan't\", \"mustn't\",\n",
    "    \"mightn't\", \"needn't\"\n",
    "}\n",
    "\n",
    "sentiment_critical.update(negative_contractions)\n",
    "\n",
    "def clean_twts(twt):\n",
    "    twt = twt.lower()\n",
    "    twt = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', twt)  # remove urls\n",
    "    twt = re.sub(r\"@\\w+\", '', twt)  # remove mentions\n",
    "    twt = re.sub(r\"#\", '', twt)  # remove hashtag symbol\n",
    "    twt = emoji.replace_emoji(twt, replace='')  # remove emojis\n",
    "    twt = re.sub(r\"[^a-zA-Z\\s']\", '', twt)  # remove punctuation\n",
    "    twt = re.sub(r\"\\s+\", ' ', twt).strip()  # clean whitespace\n",
    "\n",
    "    tokens = twt.split()\n",
    "    tokens = [word for word in tokens if (word not in stop_words or word in sentiment_critical) and len(word) > 1] # remove stopwords and keep sentiment-critical words\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # lemmatize\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "cleaned_twts = df['text'].apply(clean_twts)\n",
    "df['cleaned_text'] = cleaned_twts\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(cleaned_twts)\n",
    "sequences = tokenizer.texts_to_sequences(cleaned_twts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=20, padding='post', truncating='post')\n",
    "\n",
    "df['padded_text'] = list(padded_sequences)\n",
    "df['sentiment'] = df['sentiment'].map({4: 1, 0: 0})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_sequences\n",
    "y = df['sentiment']\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(f\"Training data: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Test data: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "print(\"Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ade10",
   "metadata": {},
   "source": [
    "Run Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0eb418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_optimization(n_trials, timeout=3600):\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=5,\n",
    "            n_warmup_steps=10\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"Starting Optuna optimization with {n_trials} trials...\")\n",
    "    print(\"This may take a while...\")\n",
    "    \n",
    "    study.optimize(\n",
    "        objective, \n",
    "        n_trials=n_trials,\n",
    "        timeout=timeout,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    return study\n",
    "\n",
    "study = run_optuna_optimization(n_trials=8)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best trial: {study.best_trial.number}\")\n",
    "print(f\"Best accuracy: {study.best_value:.4f}\")\n",
    "print(f\"Best parameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ed1373",
   "metadata": {},
   "source": [
    "Visualize optimization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_results(study):\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    trials = study.trials\n",
    "    values = [trial.value for trial in trials if trial.value is not None]\n",
    "    \n",
    "    axes[0, 0].plot(values)\n",
    "    axes[0, 0].set_title('Optimization History')\n",
    "    axes[0, 0].set_xlabel('Trial')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    if len(trials) > 10:\n",
    "        try:\n",
    "            importance = optuna.importance.get_param_importances(study)\n",
    "            params = list(importance.keys())\n",
    "            importances = list(importance.values())\n",
    "            \n",
    "            axes[0, 1].barh(params, importances)\n",
    "            axes[0, 1].set_title('Parameter Importance')\n",
    "            axes[0, 1].set_xlabel('Importance')\n",
    "        except:\n",
    "            axes[0, 1].text(0.5, 0.5, 'Not enough trials\\nfor importance analysis', \n",
    "                          ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    param_names = list(best_params.keys())\n",
    "    param_values = list(best_params.values())\n",
    "    \n",
    "    axes[1, 0].barh(param_names, param_values)\n",
    "    axes[1, 0].set_title('Best Parameters')\n",
    "    axes[1, 0].set_xlabel('Value')\n",
    "    \n",
    "    axes[1, 1].hist(values, bins=20, alpha=0.7)\n",
    "    axes[1, 1].axvline(study.best_value, color='red', linestyle='--', \n",
    "                      label=f'Best: {study.best_value:.4f}')\n",
    "    axes[1, 1].set_title('Distribution of Accuracy Scores')\n",
    "    axes[1, 1].set_xlabel('Accuracy')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_optimization_results(study)\n",
    "\n",
    "trials_df = study.trials_dataframe()\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(f\"Total trials: {len(study.trials)}\")\n",
    "print(f\"Best accuracy: {study.best_value:.4f}\")\n",
    "print(f\"Mean accuracy: {trials_df['value'].mean():.4f}\")\n",
    "print(f\"Std accuracy: {trials_df['value'].std():.4f}\")\n",
    "print(f\"Worst accuracy: {trials_df['value'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9ed6e",
   "metadata": {},
   "source": [
    "Train final model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(study, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    print(\"Training final model with best parameters:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=10000, output_dim=best_params['embedding_dim']),\n",
    "        LSTM(best_params['lstm_units'], return_sequences=False),\n",
    "        Dropout(best_params['dropout_rate']),\n",
    "        Dense(best_params['dense_units'], activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate'])\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining final model...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=12,\n",
    "        batch_size=best_params['batch_size'],\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "final_model, final_history = train_final_model(study, X_train, X_test, y_train, y_test)\n",
    "\n",
    "test_loss, test_acc = final_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nFinal test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Final test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142e903",
   "metadata": {},
   "source": [
    "Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1bc1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    final_train_acc = history.history['accuracy'][-1]\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    \n",
    "    print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "    print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "\n",
    "plot_training_history(final_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0283d",
   "metadata": {},
   "source": [
    "Save results and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# joblib.dump(study, 'optuna_study.pkl')\n",
    "# print(\"Optuna study saved as 'optuna_study.pkl'\")\n",
    "\n",
    "# best_params = study.best_params\n",
    "# best_params['best_accuracy'] = study.best_value\n",
    "# best_params['optimization_date'] = datetime.now().isoformat()\n",
    "\n",
    "# with open('best_hyperparameters.json', 'w') as f:\n",
    "#     json.dump(best_params, f, indent=2)\n",
    "# print(\"Best parameters saved as 'best_hyperparameters.json'\")\n",
    "\n",
    "# final_model.save('optimized_lstm_model.h5')\n",
    "# print(\"Final model saved as 'optimized_lstm_model.h5'\")\n",
    "\n",
    "# trials_df = study.trials_dataframe()\n",
    "# trials_df.to_csv('optuna_trials.csv', index=False)\n",
    "# print(\"Trials data saved as 'optuna_trials.csv'\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"HYPERPARAMETER OPTIMIZATION COMPLETE!\")\n",
    "# print(\"=\"*60)\n",
    "# print(f\"Best hyperparameters found:\")\n",
    "# for key, value in study.best_params.items():\n",
    "#     print(f\"  {key}: {value}\")\n",
    "# print(f\"\\nBest cross-validation accuracy: {study.best_value:.4f}\")\n",
    "# print(f\"Final test accuracy: {test_acc:.4f}\")\n",
    "# print(f\"Total trials run: {len(study.trials)}\")\n",
    "# print(\"\\nFiles saved:\")\n",
    "# print(\"  - optuna_study.pkl (complete study object)\")\n",
    "# print(\"  - best_hyperparameters.json (best parameters)\")\n",
    "# print(\"  - optimized_lstm_model.h5 (trained model)\")\n",
    "# print(\"  - optuna_trials.csv (all trial results)\")\n",
    "# print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
