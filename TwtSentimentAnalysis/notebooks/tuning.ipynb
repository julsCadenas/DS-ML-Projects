{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2978f55a",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis on Tweets**\n",
    "### Will redo this!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4f172",
   "metadata": {},
   "source": [
    "Define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_units=64, dropout_rate=0.5, dense_units=32, embedding_dim=64):\n",
    "    # lstm model with specified hyperparameters\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=10000, output_dim=embedding_dim),\n",
    "        LSTM(lstm_units, return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587f5f4",
   "metadata": {},
   "source": [
    "cross validation and hyperparameter tuning function. inefficient approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c97e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_cv(x, y, n_iterations=8, cv_folds=3):\n",
    "\n",
    "    param_ranges = {\n",
    "        'lstm_units': [32, 64, 128, 256],\n",
    "        'dropout_rate': [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "        'dense_units': [16, 32, 64, 128],\n",
    "        'embedding_dim': [32, 64, 128]\n",
    "    }\n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"Random Search: {n_iterations} iterations with {cv_folds}-fold CV\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        params = {\n",
    "            key: random.choice(values) \n",
    "            for key, values in param_ranges.items()\n",
    "        }\n",
    "        \n",
    "        print(f\"Iteration {i+1:2d}/{n_iterations}: {params}\")\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42+i)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(x, y)):\n",
    "            x_train_fold, x_val_fold = x[train_idx], x[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model = create_model(**params)\n",
    "            \n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=3,\n",
    "                restore_best_weights=True,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            history = model.fit(\n",
    "                x_train_fold, y_train_fold,\n",
    "                validation_data=(x_val_fold, y_val_fold),\n",
    "                epochs=12,\n",
    "                batch_size=32,\n",
    "                verbose=0,\n",
    "                callbacks=[early_stopping]\n",
    "            )\n",
    "            \n",
    "            best_val_acc = max(history.history['val_accuracy'])\n",
    "            fold_scores.append(best_val_acc)\n",
    "        \n",
    "        mean_score = np.mean(fold_scores)\n",
    "        std_score = np.std(fold_scores)\n",
    "        \n",
    "        all_results.append({\n",
    "            'params': params,\n",
    "            'mean_accuracy': mean_score,\n",
    "            'std_accuracy': std_score,\n",
    "            'fold_scores': fold_scores\n",
    "        })\n",
    "        \n",
    "        print(f\"              CV Accuracy: {mean_score:.4f} (Â±{std_score:.4f})\")\n",
    "        \n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = params\n",
    "            print(f\"NEW BEST!\")\n",
    "    \n",
    "    return best_params, best_score, all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d10c8",
   "metadata": {},
   "source": [
    "Run the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183fc642",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hyperparameter Tuning for LSTM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "x_combined = np.concatenate([x_train, x_val])\n",
    "y_combined = pd.concat([y_train, y_val])\n",
    "\n",
    "best_params, best_score, all_results = random_search_cv(\n",
    "    x_combined, y_combined, \n",
    "    n_iterations=8, \n",
    "    cv_folds=3\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BEST RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best CV Score: {best_score:.4f}\")\n",
    "\n",
    "print(\"\\nTraining Final Model...\")\n",
    "final_model = create_model(**best_params)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "final_history = final_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=12,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e62e20",
   "metadata": {},
   "source": [
    "Final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273dfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Cross-Validation Accuracy: {best_score:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Best Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245a514",
   "metadata": {},
   "source": [
    "Plot the results of tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7050cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(final_history.history['accuracy'], label='Training')\n",
    "plt.plot(final_history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(final_history.history['loss'], label='Training')\n",
    "plt.plot(final_history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "cv_scores = [result['mean_accuracy'] for result in all_results]\n",
    "plt.hist(cv_scores, bins=8, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(best_score, color='red', linestyle='--', linewidth=2, label=f'Best: {best_score:.4f}')\n",
    "plt.title('CV Accuracy Distribution')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce3c49",
   "metadata": {},
   "source": [
    "Print the top configurations from the tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTOP 3 CONFIGURATIONS\")\n",
    "print(\"=\" * 40)\n",
    "sorted_results = sorted(all_results, key=lambda x: x['mean_accuracy'], reverse=True)\n",
    "for i, result in enumerate(sorted_results[:3]):\n",
    "    print(f\"{i+1}. Accuracy: {result['mean_accuracy']:.4f} (Â±{result['std_accuracy']:.4f})\")\n",
    "    print(f\"   {result['params']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a83853",
   "metadata": {},
   "source": [
    "### **RESULTS**\n",
    "\n",
    "#### ðŸ¥‡ TOP 3 CONFIGURATIONS\n",
    "---\n",
    "\n",
    "1. **Accuracy:** `0.8098 Â± 0.0006`  \n",
    "   **Parameters:**  \n",
    "   `{'lstm_units': 256, 'dropout_rate': 0.6, 'dense_units': 128, 'embedding_dim': 128}`\n",
    "\n",
    "2. **Accuracy:** `0.8098 Â± 0.0002`  \n",
    "   **Parameters:**  \n",
    "   `{'lstm_units': 256, 'dropout_rate': 0.6, 'dense_units': 128, 'embedding_dim': 32}`\n",
    "\n",
    "3. **Accuracy:** `0.8097 Â± 0.0009`  \n",
    "   **Parameters:**  \n",
    "   `{'lstm_units': 256, 'dropout_rate': 0.3, 'dense_units': 128, 'embedding_dim': 32}`\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
