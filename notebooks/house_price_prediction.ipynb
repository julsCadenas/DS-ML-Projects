{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREDICTING HOUSE PRICES USING REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üì• Downloading and Extracting the Dataset**\n",
    "Before we start building our house price prediction model, we need to download the dataset from Kaggle and extract its contents.\n",
    "\n",
    "### **1Ô∏è‚É£ Install Kaggle API**  \n",
    "The Kaggle API is required to download datasets directly from Kaggle. If you haven't installed it yet, run the command below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2Ô∏è‚É£ Download the Dataset**\n",
    "\n",
    "Use the following command to download the dataset from the Kaggle competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading house-prices-advanced-regression-techniques.zip to c:\\Users\\Juls\\Desktop\\houseprice\\notebooks\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/199k [00:00<?, ?B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199k/199k [00:00<00:00, 336kB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199k/199k [00:00<00:00, 335kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c house-prices-advanced-regression-techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3Ô∏è‚É£ Extract the Dataset**\n",
    "\n",
    "The dataset is stored as a ZIP file. We need to extract it before using it in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_description.txt', 'sample_submission.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "dataset_zip = \"../data/house-prices-advanced-regression-techniques.zip\"\n",
    "dataset_folder = \"../data/raw\"\n",
    "\n",
    "with zipfile.ZipFile(dataset_zip, 'r') as folder:\n",
    "    folder.extractall(dataset_folder)\n",
    "    \n",
    "\n",
    "os.listdir(dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Loading the Dataset\n",
    "Now that we have extracted the dataset, let's load it into Pandas DataFrames for further analysis.\n",
    "\n",
    "### **1Ô∏è‚É£ Install Pandas**  \n",
    "Pandas is a powerful library for data manipulation and analysis. If you haven't installed it yet, you can do so using:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2Ô∏è‚É£ Load the Dataset into Pandas**\n",
    "\n",
    "- We will use pd.read_csv() to load both the training and test datasets.\n",
    "- The .head() function allows us to preview the first five rows of the training dataset. This helps us understand the structure of the data, including the features and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/raw/train.csv')\n",
    "test_df = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üßº Data Cleaning**\n",
    "\n",
    "This section focuses on handling missing values, detecting outliers, and preparing the dataset for modeling.\n",
    "\n",
    "### **1Ô∏è‚É£ Find columns with missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage      259\n",
      "Alley           1369\n",
      "MasVnrType       872\n",
      "MasVnrArea         8\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtFinType2      38\n",
      "Electrical         1\n",
      "FireplaceQu      690\n",
      "GarageType        81\n",
      "GarageYrBlt       81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "PoolQC          1453\n",
      "Fence           1179\n",
      "MiscFeature     1406\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = train_df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2Ô∏è‚É£ Identify feature types.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
      "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
      "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
      "       'SaleType', 'SaleCondition'],\n",
      "      dtype='object')\n",
      "Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
      "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
      "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
      "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
      "       'MiscVal', 'MoSold', 'YrSold', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = train_df.select_dtypes(include=['object']).columns\n",
    "numerical_columns = train_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "print(categorical_columns)\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3Ô∏è‚É£ Handle Missing Values.**\n",
    "\n",
    "- Drop columns with missing values greater than 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Alley', 'MasVnrType', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_values_test = test_df.isnull().sum()\n",
    "\n",
    "missing_ratio = missing_values / len(train_df)\n",
    "missing_ratio_test = missing_values_test / len(test_df)\n",
    "\n",
    "drop_cols = missing_ratio[missing_ratio > threshold].index\n",
    "train_df.drop(columns=drop_cols, inplace=True)\n",
    "test_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "print(\"Dropped columns:\", list(drop_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace missing values.\n",
    "- Replace missing values in categorical columns with the mode(most frequent element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(train_df[col].mode()[0])\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(test_df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if the numerical column is normally distributed or if it is skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a box plot to check for outliers in the numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_box_plot(df, cols_per_row):\n",
    "    num_cols = len(numerical_columns)\n",
    "    num_rows = int(np.ceil(num_cols / cols_per_row))\n",
    "\n",
    "    fig, ax = plt.subplots(num_rows, cols_per_row, figsize=(20,num_rows*5))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numerical_columns):\n",
    "        sns.boxplot(y=df[col], ax=ax[i])\n",
    "        ax[i].set_title(col)\n",
    "    \n",
    "    for i in range(num_cols, len(ax)):\n",
    "        fig.delaxes(ax[i])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "numerical_box_plot(train_df, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4Ô∏è‚É£ Handle Outliers** \n",
    "- Using inter quartile range, check if each columns contains outliers.\n",
    "- If a column contains outliers, fill the missing values with the median.\n",
    "- If a column contains 2 or less outliers, fill the missing values with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure SalePrice is not in test_df\n",
    "if 'SalePrice' in test_df.columns:\n",
    "    test_df.drop(columns=['SalePrice'], inplace=True)\n",
    "\n",
    "for col in numerical_columns:\n",
    "    if col == 'SalePrice':  # Skip SalePrice to avoid KeyError\n",
    "        continue\n",
    "\n",
    "    if train_df[col].dtype in ['int64', 'float64']:  # Ensure numerical columns\n",
    "        mean = train_df[col].mean()\n",
    "        median = train_df[col].median()\n",
    "        q1 = train_df[col].quantile(0.25)\n",
    "        q3 = train_df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "        # Count outliers in train_df\n",
    "        outliers = train_df[(train_df[col] < lower_bound) | (train_df[col] > upper_bound)].shape[0]\n",
    "        \n",
    "        # Choose filling value based on outliers\n",
    "        fill_value = mean if outliers <= 2 else median\n",
    "\n",
    "        # Assign directly instead of inplace=True (avoids FutureWarning)\n",
    "        train_df[col] = train_df[col].fillna(fill_value)\n",
    "\n",
    "        # Ensure test_df has the column before filling\n",
    "        if col in test_df.columns:\n",
    "            test_df[col] = test_df[col].fillna(fill_value)\n",
    "    else:\n",
    "        print(f\"Skipping non-numeric column: {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **‚öôÔ∏è Data Preprocessing**\n",
    "\n",
    "This section focuses on preparing the dataset for modeling by encoding categorical features and scaling numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1Ô∏è‚É£ Scale Numerical Features**\n",
    "\n",
    "- Since SalePrice is not in the test data, lets exclude it in the standardizing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaling Done!\n",
      "(1460, 75) (1459, 74)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_features = [col for col in numerical_columns if col in train_df.columns and col != \"SalePrice\"]\n",
    "\n",
    "train_df[numerical_features] = scaler.fit_transform(train_df[numerical_features])\n",
    "test_df[numerical_features] = scaler.transform(test_df[numerical_features])\n",
    "\n",
    "print(\"Feature Scaling Done!\")\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2Ô∏è‚É£ Encode Categorical Features**\n",
    "\n",
    "- Fix categorical features as we dropped columns earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Encoding Done!\n",
      "(1460, 231) (1459, 214)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = [col for col in categorical_columns if col in train_df.columns]\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns=categorical_features, drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "print(\"Categorical Encoding Done!\")\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [col for col in categorical_columns if col in train_df.columns]\n",
    "numerical_features = [col for col in numerical_columns if col in train_df.columns and col != \"SalePrice\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),  \n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features)  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üìå Training the Linear Regression Model**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1Ô∏è‚É£ Define the target and train the Linear Regression Model**\n",
    "- The target variable is **`SalePrice`**.\n",
    "- We use **Scikit-Learn's `LinearRegression`** to train our model.\n",
    "- The model learns relationships between the features and house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OneHotEncoding & Scaling Done!\n",
      "X_train shape: (1460, 230)\n",
      "X_test shape: (1459, 230)\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "\n",
    "x_train = train_df.drop(columns=['SalePrice'])\n",
    "y_train = train_df['SalePrice']\n",
    "x_test = test_df.copy()\n",
    "\n",
    "x_train = preprocessor.fit_transform(x_train)\n",
    "x_test = preprocessor.transform(x_test)\n",
    "\n",
    "print(\"‚úÖ OneHotEncoding & Scaling Done!\")\n",
    "print(\"X_train shape:\", x_train.shape)\n",
    "print(\"X_test shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Trained!\n"
     ]
    }
   ],
   "source": [
    "linear_regression.fit(x_train, y_train)\n",
    "print(\"Linear Regression Model Trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2Ô∏è‚É£ Linear Regression Model Evaluation**\n",
    "\n",
    "After training the Linear Regression model, we evaluate its performance using **MAE, MSE, RMSE, and R¬≤ score**.  \n",
    "\n",
    "#### **üìå Evaluation Metrics**  \n",
    "- **Mean Absolute Error (MAE)**: Measures the average absolute difference between predicted and actual values. Lower is better.  \n",
    "- **Mean Squared Error (MSE)**: Similar to MAE but squares the differences, penalizing larger errors more. Lower is better.  \n",
    "- **Root Mean Squared Error (RMSE)**: The square root of MSE, keeping units consistent with the target variable. Lower is better.  \n",
    "- **R¬≤ Score (R-squared)**: Indicates how well the model explains variance in the data. **Ranges from 0 to 1**, where **1 is a perfect fit**.\n",
    "- **Cross-Validation RMSE**: Evaluates model stability by splitting the training set into multiple folds and averaging RMSE across them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE: 13509.327849941874\n",
      "Training MSE: 440691048.06912225\n",
      "Training RMSE: 20992.642712843997\n",
      "Training R^2: 0.9301243347378332\n",
      "Cross-Validation RMSE: 42412.1700414257\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = linear_regression.predict(x_train)\n",
    "\n",
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "mse = (mean_squared_error(y_train, y_train_pred))\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "cv_scores = cross_val_score(linear_regression, x_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "print(f\"Training MAE: {mae}\")\n",
    "print(f\"Training MSE: {mse}\")\n",
    "print(f\"Training RMSE: {rmse}\")\n",
    "print(f\"Training R^2: {r2}\")\n",
    "print(f\"Cross-Validation RMSE: {-cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3Ô∏è‚É£ Generating Predictions and Saving to CSV**\n",
    "\n",
    "After training the Linear Regression model, we use it to make predictions on the test dataset and save the results to a CSV file for submission to [Kaggle](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "test_pred = linear_regression.predict(x_test)\n",
    "\n",
    "results = pd.DataFrame({\"Id\": test_df.index + 1461, \"SalePrice\": test_pred})\n",
    "results.to_csv(\"../data/results.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save training predictions on a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_pred predictions saved to y_results.csv\n"
     ]
    }
   ],
   "source": [
    "y_train_results = pd.DataFrame({\"Id\": train_df.index, \"SalePrice\": y_train_pred})\n",
    "y_train_results.to_csv(\"../data/y_results.csv\", index=False)\n",
    "\n",
    "print(\"y_train_pred predictions saved to y_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
